{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Neural Network for Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:27.388059Z",
     "start_time": "2018-11-22T12:18:24.433094Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from E4525_ML import text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:27.393025Z",
     "start_time": "2018-11-22T12:18:27.390033Z"
    }
   },
   "outputs": [],
   "source": [
    "seed=456\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:27.408969Z",
     "start_time": "2018-11-22T12:18:27.394995Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews_filename=os.getcwd()+\"\\\\Reviews.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:30.906655Z",
     "start_time": "2018-11-22T12:18:27.410952Z"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(reviews_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK      dll pa                     0   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time                Summary  \\\n",
       "0                       1      5  1303862400  Good Quality Dog Food   \n",
       "1                       0      1  1346976000      Not as Advertised   \n",
       "\n",
       "                                                Text  \n",
       "0  I have bought several of the Vitality canned d...  \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:30.912620Z",
     "start_time": "2018-11-22T12:18:30.908625Z"
    }
   },
   "outputs": [],
   "source": [
    "#data_dir=r\"../../data/amazon-reviews\"\n",
    "data_dir=os.getcwd()\n",
    "#model_dir=r\"../../data/models/tf/AmazonReviews_Binary_Embedding\"\n",
    "#dense_model_dir=r\"../../data/models/tf/AmazonReviews_Binary_DNN\n",
    "model_dir = os.getcwd()\n",
    "dense_model_dir= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train, Validation and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:30.931542Z",
     "start_time": "2018-11-22T12:18:30.914608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568454,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\ankur\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "documents_all=data[\"Text\"].as_matrix()\n",
    "labels_all=data[\"Score\"].as_matrix()\n",
    "print(documents_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:31.045259Z",
     "start_time": "2018-11-22T12:18:30.932535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(511608,) (56846,)\n"
     ]
    }
   ],
   "source": [
    "docs,docs_test,labels,labels_test=train_test_split(documents_all,labels_all,test_size=0.1)\n",
    "print(docs.shape,docs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:31.141974Z",
     "start_time": "2018-11-22T12:18:31.046230Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486027,) (25581,)\n"
     ]
    }
   ],
   "source": [
    "docs_train,docs_val,labels_train,labels_val=train_test_split(docs,labels,test_size=0.05)\n",
    "print(docs_train.shape,docs_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T10:54:41.615545Z",
     "start_time": "2017-12-23T10:54:41.599916Z"
    }
   },
   "source": [
    "## Text Embedding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:31.148956Z",
     "start_time": "2018-11-22T12:18:31.142972Z"
    }
   },
   "outputs": [],
   "source": [
    "countVectorizer=TfidfVectorizer(input=\"content\",decode_error=\"ignore\",\n",
    "                                       max_features=50000,\n",
    "                                       tokenizer=text.stem_tokenizer,\n",
    "                                       stop_words=text.stop_words())\n",
    "dencoder=text.DocumentEncoder(countVectorizer)  #sklearn encoder\n",
    "#object of class DocumentEncoder, now to call its functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:32.192193Z",
     "start_time": "2018-11-22T12:18:31.149953Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Project\\\\Amazon\\\\amazon_reviews.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-79ea0c4e58ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#file.close()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle_filename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mcountVectorizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtexts_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtexts_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtexts_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Project\\\\Amazon\\\\amazon_reviews.p'"
     ]
    }
   ],
   "source": [
    "#pickle_filename=data_dir+\"\\\\amazon_reviews.p\"\n",
    "if False:\n",
    "    texts_train=dencoder.fit_transform(docs_train)\n",
    "    texts_val=dencoder.transform(docs_val)\n",
    "    texts_test=dencoder.transform(docs_test)\n",
    "    \n",
    "    #file=open(pickle_filename,\"wb\")\n",
    "    #pickle.dump((countVectorizer,texts_train,labels_train,texts_val,labels_val,texts_test,labels_test),file)\n",
    "    #file.close()\n",
    "else:\n",
    "    file=open(pickle_filename,\"rb\")\n",
    "    countVectorizer,texts_train,labels_train,texts_val,labels_val,texts_test,labels_test=pickle.load(file)\n",
    "    file.close()\n",
    "print(texts_train.shape,texts_val.shape,texts_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train=dencoder.fit_transform(docs_train)\n",
    "texts_val=dencoder.transform(docs_val)\n",
    "texts_test=dencoder.transform(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486027,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([44803, 13593, 47940, 36788, 34153,  9351, 24531, 17572, 13193,\n",
       "        9643, 14300, 28088, 31308, 11587, 28797,  8446, 40548, 34153,\n",
       "       24183, 49253,  6316, 42502, 21165, 46663, 11970, 18782, 11587,\n",
       "       18468, 43340,  6436, 31441,  6530, 45450, 35687, 13593, 47940,\n",
       "       23530, 35695, 32607, 40813, 43570, 48687, 48538, 35695, 32607,\n",
       "       40679, 10450,  8228, 38300, 35258, 14233, 37844,  6436, 17760,\n",
       "       14310, 46274], dtype=int32),\n",
       "       array([22024, 36377, 18908, 13820, 14258, 44161, 32108, 42002, 30270,\n",
       "       35817, 33140, 13534, 33140, 13593, 30620,  6555, 20114, 12671,\n",
       "       39953, 48452, 21521, 35833, 17403,  7418, 22819, 30816,  9601,\n",
       "       36203, 28009, 38267], dtype=int32)], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_train[0:2]\n",
    "#these are indexed of words present in those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44803, 13593, 47940, 36788, 34153,  9351, 24531, 17572, 13193,\n",
       "        9643, 14300, 28088, 31308, 11587, 28797,  8446, 40548, 34153,\n",
       "       24183, 49253,  6316, 42502, 21165, 46663, 11970, 18782, 11587,\n",
       "       18468, 43340,  6436, 31441,  6530, 45450, 35687, 13593, 47940,\n",
       "       23530, 35695, 32607, 40813, 43570, 48687, 48538, 35695, 32607,\n",
       "       40679, 10450,  8228, 38300, 35258, 14233, 37844,  6436, 17760,\n",
       "       14310, 46274], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_train[0][0:125] #means dont take all words, but take first 125 , if not present index is -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:32.250017Z",
     "start_time": "2018-11-22T12:18:32.193163Z"
    }
   },
   "outputs": [],
   "source": [
    "ltexts=[len(text) for text in texts_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ltexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltexts.index(152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:32.438539Z",
     "start_time": "2018-11-22T12:18:32.253004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([189251., 161099.,  66112.,  30420.,  15775.,   8397.,   5174.,\n",
       "          3155.,   1873.,   1325.]),\n",
       " array([  0.,  25.,  50.,  75., 100., 125., 150., 175., 200., 225., 250.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ltexts,range=[0,250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:32.444511Z",
     "start_time": "2018-11-22T12:18:32.439505Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_texts(texts,W):\n",
    "    fragments=[]\n",
    "    fragment_labels=[]\n",
    "    for idx,text in enumerate(texts):\n",
    "            fragment=text[0:W]\n",
    "            fragment=np.pad(fragment,(W-len(fragment),0),mode=\"constant\",constant_values=-2)\n",
    "            fragments.append(fragment)\n",
    "    return np.array(fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:32.455483Z",
     "start_time": "2018-11-22T12:18:32.445489Z"
    }
   },
   "outputs": [],
   "source": [
    "W=125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:47.731613Z",
     "start_time": "2018-11-22T12:18:32.457476Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486027, 125) (486027,)\n"
     ]
    }
   ],
   "source": [
    "X_train=pad_texts(texts_train,W)\n",
    "Y_train=labels_train>3\n",
    "print(X_train.shape,Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45657, 29386, 17925, 35307, 23605, 38014, 44291, 20508, 16194,\n",
       "       43547, 24831, 43875, 17925, 31184,  7468, 23597, 32826, 13883,\n",
       "       47088, 23605, 29386, 47068, 18746, 44803, 44291, 16022, 24831,\n",
       "       10305, 36494, 33140, 17925, 35260, 44161, 10005, 33140, 48555,\n",
       "       25051, 27501, 27374, 33140, 41996, 17925, 35307, 22819, 40168,\n",
       "       43158, 27490, 20022, 18920, 13840, 13713, 41783, 39781, 37335,\n",
       "       44989, 17925, 36587, 41152, 45177, 45407, 17572, 36122,  7136,\n",
       "       10498, 10498, 45657, 29386, 37657, 17403,  5062, 15189, 15600,\n",
       "       41756, 43840,  7880, 22201, 37770, 17177, 43840, 24891, 10498,\n",
       "       10498, 32218, 13365, 43026, 18897, 18028, 17925, 17925, 42702,\n",
       "        6522, 12200, 19725, 25153, 10165, 25009, 32215, 12200, 48736,\n",
       "       10060, 12200, 28441, 24831, 12200,  8347,  8763, 47664,  6318,\n",
       "       12200, 24975, 11588, 17925, 22819, 35680, 18028, 49262, 23347,\n",
       "       27556, 43840, 42039, 37693, 47665, 10498, 10498, 17925])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train[43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45657, 29386, 17925, 35307, 23605, 38014, 44291, 20508, 16194,\n",
       "       43547, 24831, 43875, 17925, 31184,  7468, 23597, 32826, 13883,\n",
       "       47088, 23605, 29386, 47068, 18746, 44803, 44291, 16022, 24831,\n",
       "       10305, 36494, 33140, 17925, 35260, 44161, 10005, 33140, 48555,\n",
       "       25051, 27501, 27374, 33140, 41996, 17925, 35307, 22819, 40168,\n",
       "       43158, 27490, 20022, 18920, 13840, 13713, 41783, 39781, 37335,\n",
       "       44989, 17925, 36587, 41152, 45177, 45407, 17572, 36122,  7136,\n",
       "       10498, 10498, 45657, 29386, 37657, 17403,  5062, 15189, 15600,\n",
       "       41756, 43840,  7880, 22201, 37770, 17177, 43840, 24891, 10498,\n",
       "       10498, 32218, 13365, 43026, 18897, 18028, 17925, 17925, 42702,\n",
       "        6522, 12200, 19725, 25153, 10165, 25009, 32215, 12200, 48736,\n",
       "       10060, 12200, 28441, 24831, 12200,  8347,  8763, 47664,  6318,\n",
       "       12200, 24975, 11588, 17925, 22819, 35680, 18028, 49262, 23347,\n",
       "       27556, 43840, 42039, 37693, 47665, 10498, 10498, 17925,  7327,\n",
       "       22819,  7714, 36491,  6943, 37693, 36623, 17971, 29195, 23551,\n",
       "        8158,  7327, 29195, 25009, 38186, 11600, 10825, 23643, 25154,\n",
       "       14062, 17925, 47088, 14274,  7625, 28088,  5065, 48378],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_train[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:48.579347Z",
     "start_time": "2018-11-22T12:18:47.734606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25581, 125) (25581,)\n"
     ]
    }
   ],
   "source": [
    "X_val=pad_texts(texts_val,W)\n",
    "Y_val=labels_val>3\n",
    "print(X_val.shape,Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:50.404493Z",
     "start_time": "2018-11-22T12:18:48.580357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56846, 125) (56846,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test=pad_texts(texts_test,W)\n",
    "Y_test=labels_test>3\n",
    "print(X_test.shape,Y_test.shape)\n",
    "\n",
    "#all docs 125 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:50.413446Z",
     "start_time": "2018-11-22T12:18:50.406463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,\n",
       "          -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,\n",
       "          -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,\n",
       "          -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,\n",
       "          -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,\n",
       "          -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,\n",
       "          -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,    -2,\n",
       "          -2,    -2,    -2,    -2,    -2,    -2, 44803, 13593, 47940,\n",
       "       36788, 34153,  9351, 24531, 17572, 13193,  9643, 14300, 28088,\n",
       "       31308, 11587, 28797,  8446, 40548, 34153, 24183, 49253,  6316,\n",
       "       42502, 21165, 46663, 11970, 18782, 11587, 18468, 43340,  6436,\n",
       "       31441,  6530, 45450, 35687, 13593, 47940, 23530, 35695, 32607,\n",
       "       40813, 43570, 48687, 48538, 35695, 32607, 40679, 10450,  8228,\n",
       "       38300, 35258, 14233, 37844,  6436, 17760, 14310, 46274])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:50.521158Z",
     "start_time": "2018-11-22T12:18:50.415437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49999, -2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max(),X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:50.528136Z",
     "start_time": "2018-11-22T12:18:50.523150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7829926468001267"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-17T22:56:28.160230Z",
     "start_time": "2017-12-17T22:56:28.124208Z"
    }
   },
   "source": [
    "## Text Embedding Model\n",
    "\n",
    "This model is equivalent to logistic regression on the Counts features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:50.541101Z",
     "start_time": "2018-11-22T12:18:50.530130Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from E4525_ML.TFClassifier import TFClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Vocabulary is total unique words, 50002\n",
    "X (input layer) is of size 486027 *125\n",
    "Basically total documents vs first 125 indices\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:50.552074Z",
     "start_time": "2018-11-22T12:18:50.543096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 50002\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "V=len(countVectorizer.vocabulary_)+2 # one for unknown words, one for padding\n",
    "print(num_classes,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:50.564042Z",
     "start_time": "2018-11-22T12:18:50.554093Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define the neural network\n",
    "class EmbeddedNet:\n",
    "    def __init__(self,V,classes):\n",
    "        self.V=V\n",
    "        self.classes=classes\n",
    "    def __call__(self,x,in_training):\n",
    "        print(x.shape)\n",
    "        # matrix  V * K \n",
    "        embedding=tf.Variable(tf.random_uniform([self.V, self.classes],-1,1),\n",
    "                      name=\"embedding\")\n",
    "        # array of shape (V,classess) with uniform number between -1 and 1. \n",
    "        print(embedding.shape)\n",
    "        bias=tf.Variable(tf.random_uniform([self.classes],-1,1),name=\"bias\")\n",
    "        print(bias.shape)\n",
    "        # for bias, vector of size classes , between -1 and 1. \n",
    "        word_vectors=tf.nn.embedding_lookup(embedding,x+2) # because lowest index is -1 for unknown  words\n",
    "                                                           #  and -2 for padding \n",
    "        # in the parameter is embedding and x+2 is id, so looking up for values at these ids in embedding.     \n",
    "        print(word_vectors.shape)\n",
    "        #dropout = tf.layers.dropout(\n",
    "        #              inputs=word_vectors, rate=0.0, training=(in_training>0))\n",
    "        logits = tf.reduce_sum(word_vectors,axis=1) +bias\n",
    "        print(logits.shape)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:50.575013Z",
     "start_time": "2018-11-22T12:18:50.566036Z"
    }
   },
   "outputs": [],
   "source": [
    "net=EmbeddedNet(V,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:50.585998Z",
     "start_time": "2018-11-22T12:18:50.576008Z"
    }
   },
   "outputs": [],
   "source": [
    "num_steps = 10 # with a bach size of 500, we will iterate over data set 100 times\n",
    "learning_rate=0.01\n",
    "learning_rate_end=0.01\n",
    "learning_steps=5\n",
    "batch_size=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:50.595956Z",
     "start_time": "2018-11-22T12:18:50.586979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486027 None 2\n"
     ]
    }
   ],
   "source": [
    "N=X_train.shape[0]\n",
    "D=None # X.shape[1]\n",
    "K=num_classes\n",
    "print(N,D,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:50.606925Z",
     "start_time": "2018-11-22T12:18:50.597950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486027, 125) (486027,) (25581, 125) (25581,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,Y_train.shape,X_val.shape,Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:18:50.779464Z",
     "start_time": "2018-11-22T12:18:50.607923Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?)\n",
      "(50002, 2)\n",
      "(2,)\n",
      "(?, ?, 2)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "model = TFClassifier(D,K,net,\n",
    "                     model_dir=model_dir,\n",
    "                     max_iter=num_steps,\n",
    "                     learning_rate=learning_rate,\n",
    "                     learning_rate_end=learning_rate_end,\n",
    "                     learning_steps=learning_steps,\n",
    "                     summary_steps=1,\n",
    "                     batch_size=batch_size,\n",
    "                     dtype=tf.int32,\n",
    "                     use_adam_optimizer=True,\n",
    "                     X_val=X_val,\n",
    "                     Y_val=Y_val\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:20:14.996709Z",
     "start_time": "2018-11-22T12:18:50.780470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0: TRAIN Loss 101.5831, Acc 0.2271 || VAL Loss 101.5946, Acc 0.2290\n",
      "\t1: TRAIN Loss 5.2321, Acc 0.7177 || VAL Loss 5.3177, Acc 0.7189\n",
      "\t2: TRAIN Loss 0.8326, Acc 0.8225 || VAL Loss 0.8578, Acc 0.8197\n",
      "\t3: TRAIN Loss 0.5265, Acc 0.8610 || VAL Loss 0.5739, Acc 0.8529\n",
      "\t4: TRAIN Loss 0.3866, Acc 0.8826 || VAL Loss 0.4439, Acc 0.8713\n",
      "\t5: TRAIN Loss 0.3085, Acc 0.8968 || VAL Loss 0.3725, Acc 0.8819\n",
      "\t6: TRAIN Loss 0.2645, Acc 0.9061 || VAL Loss 0.3314, Acc 0.8882\n",
      "\t7: TRAIN Loss 0.2396, Acc 0.9121 || VAL Loss 0.3090, Acc 0.8921\n",
      "\t8: TRAIN Loss 0.2255, Acc 0.9160 || VAL Loss 0.2971, Acc 0.8942\n",
      "\t9: TRAIN Loss 0.2169, Acc 0.9180 || VAL Loss 0.2909, Acc 0.8950\n",
      "\t10: TRAIN Loss 0.2110, Acc 0.9200 || VAL Loss 0.2877, Acc 0.8946\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:20:15.127085Z",
     "start_time": "2018-11-22T12:20:14.997707Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_Embedding\\optimization.ckpt-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8946483718384739"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=model.predict(X_val)\n",
    "np.mean(Y_pred==Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-29T09:41:15.129928Z",
     "start_time": "2017-12-29T09:41:15.114296Z"
    }
   },
   "source": [
    "## Dense Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:20:15.135066Z",
     "start_time": "2018-11-22T12:20:15.128059Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define the neural network\n",
    "class DenseNet:\n",
    "    def __init__(self,V,classes,D,E,hidden1,hidden2):\n",
    "        self.V=V\n",
    "        self.D=D\n",
    "        self.E=E\n",
    "        self.classes=classes\n",
    "        self.hidden1=hidden1\n",
    "        self.hidden2=hidden2\n",
    "    def __call__(self,x,in_training):\n",
    "        print(x.shape)\n",
    "        embedding=tf.Variable(tf.random_uniform([self.V, self.E],-1,1),\n",
    "                      name=\"embedding\")\n",
    "        print(embedding.shape)\n",
    "        #Each word linear combination of these vectors so values between -1 to 1. \n",
    "        \n",
    "        #bias=tf.Variable(tf.random_uniform([self.classes],-1,1),name=\"bias\")\n",
    "        #print(bias.shape)\n",
    "        word_vectors=tf.nn.embedding_lookup(embedding,x+2) # because lowest index is -1 for unknown  words\n",
    "                                                           #  and -2 for padding \n",
    "        # whatever the index the X has for that document, get linear combination for those words(index)    \n",
    "        dropout0= tf.layers.dropout(\n",
    "                      inputs=word_vectors,rate=0.5,training=(in_training>0))    #50 % drop out\n",
    "        print(dropout0.shape)\n",
    "        flat_input=tf.reshape(dropout0,[-1,self.E*D])\n",
    "        print(flat_input.shape)\n",
    "        layer1 = tf.layers.dense(flat_input, self.hidden1,activation=tf.nn.relu)\n",
    "        dropout1 = tf.layers.dropout(\n",
    "                      inputs=layer1, rate=0.0, training=(in_training>0))\n",
    "        print(dropout1.shape)\n",
    "        layer2 = tf.layers.dense(dropout1, self.hidden2,activation=tf.nn.relu)\n",
    "        # Add dropout operation; 0.6 probability that element will be kept\n",
    "        dropout2 = tf.layers.dropout(\n",
    "                      inputs=layer2, rate=0.5,training=(in_training>0))\n",
    "        print(dropout2.shape)\n",
    "        logits = tf.layers.dense(dropout2, self.classes)\n",
    "        print(logits.shape)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:20:15.149027Z",
     "start_time": "2018-11-22T12:20:15.137035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486027 125 10 2\n"
     ]
    }
   ],
   "source": [
    "N=X_train.shape[0]\n",
    "D=X_train.shape[1]\n",
    "E=10\n",
    "K=num_classes\n",
    "print(N,D,E,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:20:15.160970Z",
     "start_time": "2018-11-22T12:20:15.151024Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden1=128\n",
    "hidden2=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:20:15.172974Z",
     "start_time": "2018-11-22T12:20:15.162965Z"
    }
   },
   "outputs": [],
   "source": [
    "dense_net=DenseNet(V,num_classes,D,E,hidden1,hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:20:15.183939Z",
     "start_time": "2018-11-22T12:20:15.175930Z"
    }
   },
   "outputs": [],
   "source": [
    "num_steps = 100 # with a bach size of 500, we will iterate over data set 100 times\n",
    "learning_rate=0.001\n",
    "learning_rate_end=0.001\n",
    "learning_steps=2\n",
    "batch_size=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:20:15.541952Z",
     "start_time": "2018-11-22T12:20:15.185904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 125)\n",
      "(50002, 10)\n",
      "(?, 125, 10)\n",
      "(?, 1250)\n",
      "(?, 128)\n",
      "(?, 64)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "model = TFClassifier(D,K,dense_net,\n",
    "                     model_dir=dense_model_dir,\n",
    "                     max_iter=num_steps,\n",
    "                     learning_rate=learning_rate,\n",
    "                     learning_rate_end=learning_rate_end,\n",
    "                     learning_steps=learning_steps,\n",
    "                     summary_steps=5,\n",
    "                     batch_size=batch_size,\n",
    "                     dtype=tf.int32,\n",
    "                     use_adam_optimizer=True,\n",
    "                     X_val=X_val,\n",
    "                     Y_val=Y_val\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:44:35.610465Z",
     "start_time": "2018-11-22T12:20:15.543945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0: TRAIN Loss 0.8381, Acc 0.3232 || VAL Loss 0.8402, Acc 0.3193\n",
      "\t5: TRAIN Loss 0.3313, Acc 0.8555 || VAL Loss 0.3407, Acc 0.8524\n",
      "\t10: TRAIN Loss 0.2689, Acc 0.8885 || VAL Loss 0.2847, Acc 0.8797\n",
      "\t15: TRAIN Loss 0.2457, Acc 0.8988 || VAL Loss 0.2677, Acc 0.8879\n",
      "\t20: TRAIN Loss 0.2308, Acc 0.9058 || VAL Loss 0.2595, Acc 0.8933\n",
      "\t25: TRAIN Loss 0.2146, Acc 0.9135 || VAL Loss 0.2514, Acc 0.8980\n",
      "\t30: TRAIN Loss 0.2030, Acc 0.9195 || VAL Loss 0.2468, Acc 0.9011\n",
      "\t35: TRAIN Loss 0.1922, Acc 0.9240 || VAL Loss 0.2438, Acc 0.9036\n",
      "\t40: TRAIN Loss 0.1834, Acc 0.9278 || VAL Loss 0.2395, Acc 0.9061\n",
      "\t45: TRAIN Loss 0.1743, Acc 0.9320 || VAL Loss 0.2371, Acc 0.9062\n",
      "\t50: TRAIN Loss 0.1684, Acc 0.9347 || VAL Loss 0.2363, Acc 0.9074\n",
      "\t55: TRAIN Loss 0.1616, Acc 0.9380 || VAL Loss 0.2335, Acc 0.9083\n",
      "\t60: TRAIN Loss 0.1551, Acc 0.9404 || VAL Loss 0.2337, Acc 0.9080\n",
      "\t65: TRAIN Loss 0.1507, Acc 0.9428 || VAL Loss 0.2326, Acc 0.9093\n",
      "\t70: TRAIN Loss 0.1469, Acc 0.9443 || VAL Loss 0.2315, Acc 0.9093\n",
      "\t75: TRAIN Loss 0.1416, Acc 0.9469 || VAL Loss 0.2317, Acc 0.9110\n",
      "\t80: TRAIN Loss 0.1376, Acc 0.9486 || VAL Loss 0.2295, Acc 0.9116\n",
      "\t85: TRAIN Loss 0.1337, Acc 0.9502 || VAL Loss 0.2313, Acc 0.9118\n",
      "\t90: TRAIN Loss 0.1303, Acc 0.9510 || VAL Loss 0.2324, Acc 0.9120\n",
      "\t95: TRAIN Loss 0.1280, Acc 0.9520 || VAL Loss 0.2327, Acc 0.9126\n",
      "\t100: TRAIN Loss 0.1268, Acc 0.9526 || VAL Loss 0.2310, Acc 0.9131\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T12:44:35.956431Z",
     "start_time": "2018-11-22T12:44:35.611461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9130604745709706"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=model.predict(X_val)\n",
    "np.mean(Y_pred==Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-17T22:57:20.878364Z",
     "start_time": "2017-12-17T22:57:20.862737Z"
    }
   },
   "source": [
    "### layer size optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T21:35:38.688460Z",
     "start_time": "2018-11-22T12:44:35.957428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 125)\n",
      "(50002, 10)\n",
      "(?, 125, 10)\n",
      "(?, 1250)\n",
      "(?, 128)\n",
      "(?, 64)\n",
      "(?, 2)\n",
      "\t0: TRAIN Loss 0.7601, Acc 0.4172 || VAL Loss 0.7583, Acc 0.4221\n",
      "\t10: TRAIN Loss 0.2667, Acc 0.8876 || VAL Loss 0.2839, Acc 0.8796\n",
      "\t20: TRAIN Loss 0.2251, Acc 0.9094 || VAL Loss 0.2561, Acc 0.8944\n",
      "\t30: TRAIN Loss 0.1991, Acc 0.9212 || VAL Loss 0.2471, Acc 0.9011\n",
      "\t40: TRAIN Loss 0.1779, Acc 0.9305 || VAL Loss 0.2389, Acc 0.9049\n",
      "\t50: TRAIN Loss 0.1631, Acc 0.9370 || VAL Loss 0.2328, Acc 0.9070\n",
      "\t60: TRAIN Loss 0.1539, Acc 0.9414 || VAL Loss 0.2316, Acc 0.9087\n",
      "\t70: TRAIN Loss 0.1432, Acc 0.9458 || VAL Loss 0.2306, Acc 0.9108\n",
      "\t80: TRAIN Loss 0.1356, Acc 0.9490 || VAL Loss 0.2301, Acc 0.9114\n",
      "\t90: TRAIN Loss 0.1294, Acc 0.9516 || VAL Loss 0.2319, Acc 0.9120\n",
      "\t100: TRAIN Loss 0.1240, Acc 0.9538 || VAL Loss 0.2311, Acc 0.9126\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 128 64 0.9537741730397694 0.9126304679254134\n",
      "(?, 125)\n",
      "(50002, 10)\n",
      "(?, 125, 10)\n",
      "(?, 1250)\n",
      "(?, 128)\n",
      "(?, 128)\n",
      "(?, 2)\n",
      "\t0: TRAIN Loss 0.6391, Acc 0.6620 || VAL Loss 0.6420, Acc 0.6607\n",
      "\t10: TRAIN Loss 0.2647, Acc 0.8899 || VAL Loss 0.2840, Acc 0.8819\n",
      "\t20: TRAIN Loss 0.2239, Acc 0.9105 || VAL Loss 0.2574, Acc 0.8946\n",
      "\t30: TRAIN Loss 0.1992, Acc 0.9222 || VAL Loss 0.2445, Acc 0.9013\n",
      "\t40: TRAIN Loss 0.1817, Acc 0.9294 || VAL Loss 0.2394, Acc 0.9052\n",
      "\t50: TRAIN Loss 0.1674, Acc 0.9360 || VAL Loss 0.2351, Acc 0.9071\n",
      "\t60: TRAIN Loss 0.1567, Acc 0.9404 || VAL Loss 0.2321, Acc 0.9085\n",
      "\t70: TRAIN Loss 0.1487, Acc 0.9443 || VAL Loss 0.2295, Acc 0.9102\n",
      "\t80: TRAIN Loss 0.1407, Acc 0.9474 || VAL Loss 0.2316, Acc 0.9109\n",
      "\t90: TRAIN Loss 0.1349, Acc 0.9502 || VAL Loss 0.2294, Acc 0.9118\n",
      "\t100: TRAIN Loss 0.1279, Acc 0.9527 || VAL Loss 0.2315, Acc 0.9123\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 128 128 0.9526775261456668 0.9123177358195536\n",
      "(?, 125)\n",
      "(50002, 10)\n",
      "(?, 125, 10)\n",
      "(?, 1250)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "(?, 2)\n",
      "\t0: TRAIN Loss 0.8189, Acc 0.2665 || VAL Loss 0.8188, Acc 0.2689\n",
      "\t10: TRAIN Loss 0.2629, Acc 0.8909 || VAL Loss 0.2815, Acc 0.8826\n",
      "\t20: TRAIN Loss 0.2206, Acc 0.9122 || VAL Loss 0.2549, Acc 0.8960\n",
      "\t30: TRAIN Loss 0.1966, Acc 0.9235 || VAL Loss 0.2446, Acc 0.9016\n",
      "\t40: TRAIN Loss 0.1790, Acc 0.9310 || VAL Loss 0.2402, Acc 0.9038\n",
      "\t50: TRAIN Loss 0.1649, Acc 0.9372 || VAL Loss 0.2365, Acc 0.9068\n",
      "\t60: TRAIN Loss 0.1547, Acc 0.9413 || VAL Loss 0.2345, Acc 0.9079\n",
      "\t70: TRAIN Loss 0.1467, Acc 0.9452 || VAL Loss 0.2335, Acc 0.9097\n",
      "\t80: TRAIN Loss 0.1389, Acc 0.9479 || VAL Loss 0.2326, Acc 0.9114\n",
      "\t90: TRAIN Loss 0.1320, Acc 0.9512 || VAL Loss 0.2317, Acc 0.9120\n",
      "\t100: TRAIN Loss 0.1269, Acc 0.9526 || VAL Loss 0.2331, Acc 0.9117\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 128 256 0.952634318669539 0.911692271607834\n",
      "(?, 125)\n",
      "(50002, 10)\n",
      "(?, 125, 10)\n",
      "(?, 1250)\n",
      "(?, 256)\n",
      "(?, 64)\n",
      "(?, 2)\n",
      "\t0: TRAIN Loss 0.7158, Acc 0.5128 || VAL Loss 0.7143, Acc 0.5130\n",
      "\t10: TRAIN Loss 0.2621, Acc 0.8908 || VAL Loss 0.2822, Acc 0.8807\n",
      "\t20: TRAIN Loss 0.2169, Acc 0.9132 || VAL Loss 0.2550, Acc 0.8955\n",
      "\t30: TRAIN Loss 0.1845, Acc 0.9281 || VAL Loss 0.2409, Acc 0.9037\n",
      "\t40: TRAIN Loss 0.1634, Acc 0.9374 || VAL Loss 0.2357, Acc 0.9063\n",
      "\t50: TRAIN Loss 0.1505, Acc 0.9432 || VAL Loss 0.2335, Acc 0.9079\n",
      "\t60: TRAIN Loss 0.1376, Acc 0.9489 || VAL Loss 0.2310, Acc 0.9098\n",
      "\t70: TRAIN Loss 0.1281, Acc 0.9525 || VAL Loss 0.2318, Acc 0.9120\n",
      "\t80: TRAIN Loss 0.1210, Acc 0.9562 || VAL Loss 0.2305, Acc 0.9123\n",
      "\t90: TRAIN Loss 0.1148, Acc 0.9590 || VAL Loss 0.2296, Acc 0.9131\n",
      "\t100: TRAIN Loss 0.1085, Acc 0.9617 || VAL Loss 0.2308, Acc 0.9140\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 256 64 0.961658508683674 0.9139595793753176\n",
      "(?, 125)\n",
      "(50002, 10)\n",
      "(?, 125, 10)\n",
      "(?, 1250)\n",
      "(?, 256)\n",
      "(?, 128)\n",
      "(?, 2)\n",
      "\t0: TRAIN Loss 0.6395, Acc 0.6806 || VAL Loss 0.6385, Acc 0.6815\n",
      "\t10: TRAIN Loss 0.2587, Acc 0.8939 || VAL Loss 0.2791, Acc 0.8840\n",
      "\t20: TRAIN Loss 0.2097, Acc 0.9166 || VAL Loss 0.2519, Acc 0.8976\n",
      "\t30: TRAIN Loss 0.1820, Acc 0.9305 || VAL Loss 0.2395, Acc 0.9040\n",
      "\t40: TRAIN Loss 0.1621, Acc 0.9395 || VAL Loss 0.2343, Acc 0.9080\n",
      "\t50: TRAIN Loss 0.1485, Acc 0.9447 || VAL Loss 0.2341, Acc 0.9086\n",
      "\t60: TRAIN Loss 0.1362, Acc 0.9502 || VAL Loss 0.2324, Acc 0.9106\n",
      "\t70: TRAIN Loss 0.1264, Acc 0.9534 || VAL Loss 0.2326, Acc 0.9116\n",
      "\t80: TRAIN Loss 0.1198, Acc 0.9569 || VAL Loss 0.2303, Acc 0.9116\n",
      "\t90: TRAIN Loss 0.1117, Acc 0.9602 || VAL Loss 0.2351, Acc 0.9134\n",
      "\t100: TRAIN Loss 0.1092, Acc 0.9619 || VAL Loss 0.2337, Acc 0.9135\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 256 128 0.961934213531347 0.9134513897032954\n",
      "(?, 125)\n",
      "(50002, 10)\n",
      "(?, 125, 10)\n",
      "(?, 1250)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "(?, 2)\n",
      "\t0: TRAIN Loss 0.5909, Acc 0.7299 || VAL Loss 0.5941, Acc 0.7236\n",
      "\t10: TRAIN Loss 0.2662, Acc 0.8891 || VAL Loss 0.2851, Acc 0.8800\n",
      "\t20: TRAIN Loss 0.2206, Acc 0.9117 || VAL Loss 0.2573, Acc 0.8937\n",
      "\t30: TRAIN Loss 0.1938, Acc 0.9238 || VAL Loss 0.2465, Acc 0.9003\n",
      "\t40: TRAIN Loss 0.1739, Acc 0.9325 || VAL Loss 0.2418, Acc 0.9038\n",
      "\t50: TRAIN Loss 0.1587, Acc 0.9399 || VAL Loss 0.2371, Acc 0.9077\n",
      "\t60: TRAIN Loss 0.1456, Acc 0.9448 || VAL Loss 0.2356, Acc 0.9092\n",
      "\t70: TRAIN Loss 0.1352, Acc 0.9492 || VAL Loss 0.2363, Acc 0.9113\n",
      "\t80: TRAIN Loss 0.1288, Acc 0.9522 || VAL Loss 0.2362, Acc 0.9126\n",
      "\t90: TRAIN Loss 0.1217, Acc 0.9554 || VAL Loss 0.2352, Acc 0.9140\n",
      "\t100: TRAIN Loss 0.1146, Acc 0.9582 || VAL Loss 0.2362, Acc 0.9140\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 256 256 0.9581772206070857 0.9139986708885501\n",
      "(?, 125)\n",
      "(50002, 15)\n",
      "(?, 125, 15)\n",
      "(?, 1875)\n",
      "(?, 128)\n",
      "(?, 64)\n",
      "(?, 2)\n",
      "\t0: TRAIN Loss 0.8924, Acc 0.3085 || VAL Loss 0.8888, Acc 0.3132\n",
      "\t10: TRAIN Loss 0.2562, Acc 0.8936 || VAL Loss 0.2778, Acc 0.8842\n",
      "\t20: TRAIN Loss 0.2156, Acc 0.9137 || VAL Loss 0.2532, Acc 0.8969\n",
      "\t30: TRAIN Loss 0.1864, Acc 0.9270 || VAL Loss 0.2422, Acc 0.9024\n",
      "\t40: TRAIN Loss 0.1644, Acc 0.9364 || VAL Loss 0.2366, Acc 0.9068\n",
      "\t50: TRAIN Loss 0.1472, Acc 0.9438 || VAL Loss 0.2349, Acc 0.9095\n",
      "\t60: TRAIN Loss 0.1356, Acc 0.9493 || VAL Loss 0.2339, Acc 0.9105\n",
      "\t70: TRAIN Loss 0.1254, Acc 0.9538 || VAL Loss 0.2335, Acc 0.9120\n",
      "\t80: TRAIN Loss 0.1186, Acc 0.9568 || VAL Loss 0.2311, Acc 0.9139\n",
      "\t90: TRAIN Loss 0.1115, Acc 0.9599 || VAL Loss 0.2339, Acc 0.9144\n",
      "\t100: TRAIN Loss 0.1030, Acc 0.9630 || VAL Loss 0.2351, Acc 0.9156\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 128 64 0.963008227937954 0.9155623314178492\n",
      "(?, 125)\n",
      "(50002, 15)\n",
      "(?, 125, 15)\n",
      "(?, 1875)\n",
      "(?, 128)\n",
      "(?, 128)\n",
      "(?, 2)\n",
      "\t0: TRAIN Loss 0.5584, Acc 0.7686 || VAL Loss 0.5616, Acc 0.7667\n",
      "\t10: TRAIN Loss 0.2559, Acc 0.8960 || VAL Loss 0.2762, Acc 0.8860\n",
      "\t20: TRAIN Loss 0.2167, Acc 0.9155 || VAL Loss 0.2535, Acc 0.8979\n",
      "\t30: TRAIN Loss 0.1898, Acc 0.9261 || VAL Loss 0.2434, Acc 0.9022\n",
      "\t40: TRAIN Loss 0.1709, Acc 0.9353 || VAL Loss 0.2402, Acc 0.9056\n",
      "\t50: TRAIN Loss 0.1546, Acc 0.9417 || VAL Loss 0.2389, Acc 0.9081\n",
      "\t60: TRAIN Loss 0.1425, Acc 0.9467 || VAL Loss 0.2375, Acc 0.9107\n",
      "\t70: TRAIN Loss 0.1339, Acc 0.9502 || VAL Loss 0.2376, Acc 0.9125\n",
      "\t80: TRAIN Loss 0.1266, Acc 0.9538 || VAL Loss 0.2350, Acc 0.9138\n",
      "\t90: TRAIN Loss 0.1177, Acc 0.9571 || VAL Loss 0.2375, Acc 0.9144\n",
      "\t100: TRAIN Loss 0.1124, Acc 0.9593 || VAL Loss 0.2353, Acc 0.9157\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 128 128 0.9592944424898205 0.9156796059575466\n",
      "(?, 125)\n",
      "(50002, 15)\n",
      "(?, 125, 15)\n",
      "(?, 1875)\n",
      "(?, 128)\n",
      "(?, 256)\n",
      "(?, 2)\n",
      "\t0: TRAIN Loss 0.5374, Acc 0.7783 || VAL Loss 0.5398, Acc 0.7748\n",
      "\t10: TRAIN Loss 0.2443, Acc 0.9009 || VAL Loss 0.2733, Acc 0.8875\n",
      "\t20: TRAIN Loss 0.2032, Acc 0.9212 || VAL Loss 0.2522, Acc 0.8980\n",
      "\t30: TRAIN Loss 0.1815, Acc 0.9300 || VAL Loss 0.2457, Acc 0.9015\n",
      "\t40: TRAIN Loss 0.1655, Acc 0.9372 || VAL Loss 0.2414, Acc 0.9056\n",
      "\t50: TRAIN Loss 0.1527, Acc 0.9426 || VAL Loss 0.2399, Acc 0.9077\n",
      "\t60: TRAIN Loss 0.1443, Acc 0.9458 || VAL Loss 0.2410, Acc 0.9077\n",
      "\t70: TRAIN Loss 0.1365, Acc 0.9488 || VAL Loss 0.2399, Acc 0.9086\n",
      "\t80: TRAIN Loss 0.1290, Acc 0.9528 || VAL Loss 0.2363, Acc 0.9101\n",
      "\t90: TRAIN Loss 0.1226, Acc 0.9556 || VAL Loss 0.2371, Acc 0.9111\n",
      "\t100: TRAIN Loss 0.1153, Acc 0.9576 || VAL Loss 0.2385, Acc 0.9129\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 128 256 0.9575723159412954 0.9128650170048083\n",
      "(?, 125)\n",
      "(50002, 15)\n",
      "(?, 125, 15)\n",
      "(?, 1875)\n",
      "(?, 256)\n",
      "(?, 64)\n",
      "(?, 2)\n",
      "\t0: TRAIN Loss 0.6024, Acc 0.7239 || VAL Loss 0.6045, Acc 0.7212\n",
      "\t10: TRAIN Loss 0.2475, Acc 0.8984 || VAL Loss 0.2728, Acc 0.8860\n",
      "\t20: TRAIN Loss 0.1973, Acc 0.9238 || VAL Loss 0.2466, Acc 0.9007\n",
      "\t30: TRAIN Loss 0.1638, Acc 0.9370 || VAL Loss 0.2385, Acc 0.9066\n",
      "\t40: TRAIN Loss 0.1409, Acc 0.9479 || VAL Loss 0.2342, Acc 0.9103\n",
      "\t50: TRAIN Loss 0.1256, Acc 0.9539 || VAL Loss 0.2359, Acc 0.9122\n",
      "\t60: TRAIN Loss 0.1128, Acc 0.9596 || VAL Loss 0.2361, Acc 0.9135\n",
      "\t70: TRAIN Loss 0.1030, Acc 0.9640 || VAL Loss 0.2366, Acc 0.9155\n",
      "\t80: TRAIN Loss 0.0960, Acc 0.9663 || VAL Loss 0.2409, Acc 0.9156\n",
      "\t90: TRAIN Loss 0.0903, Acc 0.9689 || VAL Loss 0.2408, Acc 0.9173\n",
      "\t100: TRAIN Loss 0.0834, Acc 0.9716 || VAL Loss 0.2382, Acc 0.9179\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 256 64 0.9716373781703486 0.9179078222117978\n",
      "(?, 125)\n",
      "(50002, 15)\n",
      "(?, 125, 15)\n",
      "(?, 1875)\n",
      "(?, 256)\n",
      "(?, 128)\n",
      "(?, 2)\n",
      "\t0: TRAIN Loss 0.6461, Acc 0.6426 || VAL Loss 0.6462, Acc 0.6425\n",
      "\t10: TRAIN Loss 0.2558, Acc 0.8953 || VAL Loss 0.2769, Acc 0.8841\n",
      "\t20: TRAIN Loss 0.2128, Acc 0.9158 || VAL Loss 0.2529, Acc 0.8972\n",
      "\t30: TRAIN Loss 0.1845, Acc 0.9275 || VAL Loss 0.2424, Acc 0.9027\n",
      "\t40: TRAIN Loss 0.1581, Acc 0.9389 || VAL Loss 0.2363, Acc 0.9082\n",
      "\t50: TRAIN Loss 0.1399, Acc 0.9472 || VAL Loss 0.2317, Acc 0.9121\n",
      "\t60: TRAIN Loss 0.1249, Acc 0.9540 || VAL Loss 0.2309, Acc 0.9145\n",
      "\t70: TRAIN Loss 0.1131, Acc 0.9593 || VAL Loss 0.2293, Acc 0.9164\n",
      "\t80: TRAIN Loss 0.1039, Acc 0.9622 || VAL Loss 0.2336, Acc 0.9164\n",
      "\t90: TRAIN Loss 0.0951, Acc 0.9661 || VAL Loss 0.2364, Acc 0.9174\n",
      "\t100: TRAIN Loss 0.0897, Acc 0.9684 || VAL Loss 0.2384, Acc 0.9194\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 256 128 0.968437967438023 0.9193542082013995\n",
      "(?, 125)\n",
      "(50002, 15)\n",
      "(?, 125, 15)\n",
      "(?, 1875)\n",
      "(?, 256)\n",
      "(?, 256)\n",
      "(?, 2)\n",
      "\t0: TRAIN Loss 0.5471, Acc 0.7783 || VAL Loss 0.5503, Acc 0.7743\n",
      "\t10: TRAIN Loss 0.2418, Acc 0.9027 || VAL Loss 0.2713, Acc 0.8881\n",
      "\t20: TRAIN Loss 0.1944, Acc 0.9248 || VAL Loss 0.2499, Acc 0.8979\n",
      "\t30: TRAIN Loss 0.1652, Acc 0.9368 || VAL Loss 0.2409, Acc 0.9049\n",
      "\t40: TRAIN Loss 0.1459, Acc 0.9446 || VAL Loss 0.2417, Acc 0.9075\n",
      "\t50: TRAIN Loss 0.1314, Acc 0.9519 || VAL Loss 0.2389, Acc 0.9111\n",
      "\t60: TRAIN Loss 0.1201, Acc 0.9572 || VAL Loss 0.2374, Acc 0.9123\n",
      "\t70: TRAIN Loss 0.1111, Acc 0.9604 || VAL Loss 0.2410, Acc 0.9126\n",
      "\t80: TRAIN Loss 0.1035, Acc 0.9628 || VAL Loss 0.2459, Acc 0.9138\n",
      "\t90: TRAIN Loss 0.0954, Acc 0.9664 || VAL Loss 0.2457, Acc 0.9149\n",
      "\t100: TRAIN Loss 0.0912, Acc 0.9682 || VAL Loss 0.2497, Acc 0.9147\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 256 256 0.9681890100755719 0.9146632266135022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for E in [10,15]:\n",
    "  for hidden1 in [128,256]:\n",
    "    for hidden2 in [64,128,256]:\n",
    "        # Build the Estimator\n",
    "        dense_net=DenseNet(V,num_classes,D,E,hidden1,hidden2)\n",
    "        # Build the Estimator\n",
    "        model = TFClassifier(D,K,dense_net,\n",
    "                     model_dir=dense_model_dir,\n",
    "                     max_iter=num_steps,\n",
    "                     learning_rate=learning_rate,\n",
    "                     learning_rate_end=learning_rate_end,\n",
    "                     learning_steps=learning_steps,\n",
    "                             \n",
    "                     summary_steps=10,\n",
    "                     batch_size=batch_size,\n",
    "                     dtype=tf.int32,\n",
    "                     use_adam_optimizer=True,\n",
    "                     X_val=X_val,\n",
    "                     Y_val=Y_val\n",
    "                    )\n",
    "        model.fit(X_train,Y_train)\n",
    "        Y_pred=model.predict(X_train)\n",
    "        acc_train=np.mean(Y_pred==Y_train)\n",
    "        Y_pred=model.predict(X_val)\n",
    "        acc_val=np.mean(Y_pred==Y_val)\n",
    "        print(E,hidden1,hidden2,acc_train,acc_val)\n",
    "        results.append((E,hidden1,hidden2,acc_train,acc_val))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T21:35:38.694443Z",
     "start_time": "2018-11-22T21:35:38.690454Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T21:35:38.734337Z",
     "start_time": "2018-11-22T21:35:38.697436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>layer1</th>\n",
       "      <th>layer2</th>\n",
       "      <th>train</th>\n",
       "      <th>valuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>0.953774</td>\n",
       "      <td>0.912630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.952678</td>\n",
       "      <td>0.912318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.952634</td>\n",
       "      <td>0.911692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>0.961659</td>\n",
       "      <td>0.913960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>0.961934</td>\n",
       "      <td>0.913451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    E  layer1  layer2     train  valuation\n",
       "0  10     128      64  0.953774   0.912630\n",
       "1  10     128     128  0.952678   0.912318\n",
       "2  10     128     256  0.952634   0.911692\n",
       "3  10     256      64  0.961659   0.913960\n",
       "4  10     256     128  0.961934   0.913451"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame(results,columns=[\"E\",\"layer1\",\"layer2\",\"train\",\"valuation\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T21:35:38.761265Z",
     "start_time": "2018-11-22T21:35:38.736332Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(model_dir+\"/DNN_Binary_Text_AmazonReviews.csv\")\n",
    "val_error=data[[\"E\",\"layer1\",\"layer2\",\"valuation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T21:35:38.769244Z",
     "start_time": "2018-11-22T21:35:38.764257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9193542082013995"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"valuation\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T21:35:38.791184Z",
     "start_time": "2018-11-22T21:35:38.771238Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "E             15.000000\n",
       "layer1       256.000000\n",
       "layer2       128.000000\n",
       "train          0.968438\n",
       "valuation      0.919354\n",
       "Name: 10, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best=data.iloc[data[\"valuation\"].argmax()]\n",
    "best_E=int(best[\"E\"])\n",
    "best_hidden1=int(best[\"layer1\"])\n",
    "best_hidden2=int(best[\"layer2\"])\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The best model achieves 91.7% accuracy using and embedding of size 15, and two dense layers of 256 and 128 units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-17T22:59:13.144106Z",
     "start_time": "2017-12-17T22:59:13.128480Z"
    }
   },
   "source": [
    "### Test of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T21:35:38.811132Z",
     "start_time": "2018-11-22T21:35:38.793180Z"
    }
   },
   "outputs": [],
   "source": [
    "dense_net=DenseNet(V,num_classes,D,best_E,best_hidden1,best_hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T21:35:38.831079Z",
     "start_time": "2018-11-22T21:35:38.813127Z"
    }
   },
   "outputs": [],
   "source": [
    "num_steps = 100 # with a bach size of 500, we will iterate over data set 100 times\n",
    "learning_rate=0.001\n",
    "learning_rate_end=0.001\n",
    "learning_steps=2\n",
    "batch_size=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T21:35:39.037526Z",
     "start_time": "2018-11-22T21:35:38.833073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(511608, 125) (511608,) (56846, 125) (56846,)\n"
     ]
    }
   ],
   "source": [
    "X=np.concatenate([X_train,X_val])\n",
    "Y=np.concatenate([Y_train,Y_val])\n",
    "print(X.shape,Y.shape,X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T21:35:40.190444Z",
     "start_time": "2018-11-22T21:35:39.039521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 125)\n",
      "(50002, 15)\n",
      "(?, 125, 15)\n",
      "(?, 1875)\n",
      "(?, 256)\n",
      "(?, 128)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "model = TFClassifier(D,K,dense_net,\n",
    "                     model_dir=dense_model_dir,\n",
    "                     max_iter=num_steps,\n",
    "                     learning_rate=learning_rate,\n",
    "                     learning_rate_end=learning_rate_end,\n",
    "                     learning_steps=learning_steps,\n",
    "                             \n",
    "                     summary_steps=10,\n",
    "                     batch_size=batch_size,\n",
    "                     dtype=tf.int32,\n",
    "                     use_adam_optimizer=True,\n",
    "                     X_val=X_test,\n",
    "                     Y_val=Y_test\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is a **very large**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T22:34:08.349698Z",
     "start_time": "2018-11-22T21:35:40.192439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0: TRAIN Loss 0.5645, Acc 0.7772 || VAL Loss 0.5612, Acc 0.7796\n",
      "\t10: TRAIN Loss 0.2522, Acc 0.8947 || VAL Loss 0.2676, Acc 0.8871\n",
      "\t20: TRAIN Loss 0.2043, Acc 0.9191 || VAL Loss 0.2412, Acc 0.9018\n",
      "\t30: TRAIN Loss 0.1698, Acc 0.9345 || VAL Loss 0.2306, Acc 0.9090\n",
      "\t40: TRAIN Loss 0.1451, Acc 0.9445 || VAL Loss 0.2263, Acc 0.9130\n",
      "\t50: TRAIN Loss 0.1269, Acc 0.9531 || VAL Loss 0.2264, Acc 0.9157\n",
      "\t60: TRAIN Loss 0.1157, Acc 0.9580 || VAL Loss 0.2263, Acc 0.9167\n",
      "\t70: TRAIN Loss 0.1047, Acc 0.9632 || VAL Loss 0.2246, Acc 0.9188\n",
      "\t80: TRAIN Loss 0.0951, Acc 0.9662 || VAL Loss 0.2284, Acc 0.9194\n",
      "\t90: TRAIN Loss 0.0881, Acc 0.9691 || VAL Loss 0.2327, Acc 0.9204\n",
      "\t100: TRAIN Loss 0.0860, Acc 0.9709 || VAL Loss 0.2301, Acc 0.9204\n"
     ]
    }
   ],
   "source": [
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-22T22:34:09.145569Z",
     "start_time": "2018-11-22T22:34:08.351692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../data/models/tf/AmazonReviews_Binary_DNN\\optimization.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9203637898884706"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=model.predict(X_test)\n",
    "np.mean(Y_pred==Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we achieve 92% accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
